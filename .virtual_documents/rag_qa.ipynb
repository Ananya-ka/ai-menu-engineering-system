pip install -U langchain langchain-community langchain-openai



pip install -U langchain


import os
os.environ["OPENAI_API_KEY"] = "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"



import time

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

from langchain_openai import ChatOpenAI

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser






embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vectorstore = FAISS.load_local(
    "faiss_index",
    embedding_model,
    allow_dangerous_deserialization=True
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

print("Retriever ready:", retriever)



llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
)


prompt = PromptTemplate(
    template="""
You are an AI Menu Engineering Analyst.

RULES:
- Use ONLY the provided POS data context.
- When asked about "most profitable", rank by TOTAL PROFIT, not margin.
- Do not guess or infer beyond the data.
- If the answer is unclear, say "Not enough data".
- When multiple items are relevant, list only the top 2 based on the primary metric.


Context:
{context}

Question:
{question}

Answer clearly and concisely for a business stakeholder.
""",
    input_variables=["context", "question"]
)




retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
rag_chain = (
    {
        "context": retriever,
        "question": lambda x: x
    }
    | prompt
    | llm
    | StrOutputParser()
)





queries = [
    "Which menu items are most profitable and should be promoted?",
    "Which items sell well but have low margins?",
    "Which items should be reconsidered due to long preparation times?"
]

for q in queries:
    start = time.time()
    answer = rag_chain.invoke(q)
    latency = time.time() - start

    print(f"\nQUESTION: {q}")
    print("ANSWER:")
    print(answer)
    print(f"Latency: {latency:.2f} seconds")







